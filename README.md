<p align="center">
<!--   <img src="./imgs/bishopDL.jpg" width="120"/> -->
  <h1>Kevork Sulahianâ€™s ML Journey</h1>
  <p>Exploring C, LLMs, evals, and everything in between.</p>
  <a href="https://github.com/KevorkSulahian/kevorksulahian-ml_journey/stargazers">
  </a>
</p>

## ğŸ“‘ Table of Contents
- [About](#about)  
- [Structure](#%EF%B8%8F-structure)  
- [âœ… Completed projects/code and learning](#-completed-projectscode)  
- [ğŸ“ my articles](#-my-articles)  
- [ğŸš§ Things I'm working on right now](#-things-im-working-on-right-now)  
- [ğŸ’¡ Self-improvement guides](#self-improvement-guides)  
- [ğŸ“š Completed stuff that I recommend](#-completed-stuff-that-i-recommend)  
- [ğŸ† tiny achievements](#tiny-achievements)  
- [ğŸ”® To do in the future](#to-do-in-the-future)  
- [âœ¨ Maybe things](#maybe-things)  

## About
This will be my own journey of learning to be better at ML. This is meant to encourage me to learn and build more often.  
My [2d resume is here](https://kevorksulahian.github.io/2d-portfolio/)

* The [`C`](./C) folder in this directory is for the [cc4e.com](https://cc4e.com) class. More coming soon.  
* The [`Karapathy`](./Karapathy) folder is for the Karapathy learning videos.  
* And I am doing my experiments in the [`random_code`](./random_code/) folder. I will try to add more explanations once I have themâ€”venv will probably be missing for most of them ğŸ˜Š.

## ğŸ—ï¸ Structure
```text
kevorksulahian-ml_journey/
â”œâ”€â”€ README.md
â”œâ”€â”€ articles/
â”œâ”€â”€ C/
â”œâ”€â”€ imgs/
â”œâ”€â”€ Karapathy/
â”œâ”€â”€ random_code/
â””â”€â”€ resume/
```
<details>
<summary>ğŸ”½ Expand full tree</summary>

```text
kevorksulahian-ml_journey/
â”œâ”€â”€ README.md
â”œâ”€â”€ articles/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ demystifying-deepseekmaths/
â”‚       â”œâ”€â”€ deepseek_fasttext.ipynb
â”‚       â””â”€â”€ deepseek_fasttext.md
â”œâ”€â”€ C/
â”‚   â”œâ”€â”€ chapter_1/
â”‚   â”‚   â”œâ”€â”€ build/
â”‚   â”‚   â”œâ”€â”€ Celsius-Fahrenheit
â”‚   â”‚   â”œâ”€â”€ Celsius-Fahrenheit.c
â”‚   â”‚   â”œâ”€â”€ char_counter.c
â”‚   â”‚   â”œâ”€â”€ Fahrenheit-Celsius
â”‚   â”‚   â”œâ”€â”€ Fahrenheit-Celsius.c
â”‚   â”‚   â”œâ”€â”€ file_copy
â”‚   â”‚   â”œâ”€â”€ file_copy.c
â”‚   â”‚   â”œâ”€â”€ hello
â”‚   â”‚   â”œâ”€â”€ hello.c
â”‚   â”‚   â”œâ”€â”€ num_occ
â”‚   â”‚   â””â”€â”€ num_occ.c
â”‚   â”œâ”€â”€ chapter_2/
â”‚   â”‚   â”œâ”€â”€ 2.2.c
â”‚   â”‚   â”œâ”€â”€ sum_avg.c
â”‚   â”‚   â””â”€â”€ to_lower.c
â”‚   â”œâ”€â”€ chapter_3/
â”‚   â”‚   â”œâ”€â”€ calc.c
â”‚   â”‚   â”œâ”€â”€ expand.c
â”‚   â”‚   â””â”€â”€ itob.c
â”‚   â”œâ”€â”€ chapter_4/
â”‚   â”‚   â””â”€â”€ excercise.c
â”‚   â”œâ”€â”€ chapter_5/
â”‚   â”‚   â”œâ”€â”€ find_patern.c
â”‚   â”‚   â”œâ”€â”€ find_pattern.exe
â”‚   â”‚   â”œâ”€â”€ get_int.c
â”‚   â”‚   â”œâ”€â”€ get_int.exe
â”‚   â”‚   â”œâ”€â”€ lbs290
â”‚   â”‚   â””â”€â”€ lbs290.c
â”‚   â”œâ”€â”€ chapter_6/
â”‚   â”‚   â”œâ”€â”€ date.c
â”‚   â”‚   â”œâ”€â”€ dll.c
â”‚   â”‚   â””â”€â”€ make_and_find_linkedlist.c
â”‚   â”œâ”€â”€ chapter_7/
â”‚   â”‚   â”œâ”€â”€ ex1.c
â”‚   â”‚   â””â”€â”€ ex2.c
â”‚   â”œâ”€â”€ first_project/
â”‚   â”‚   â”œâ”€â”€ main.c
â”‚   â”‚   â”œâ”€â”€ main.exe
â”‚   â”‚   â””â”€â”€ test.txt
â”‚   â””â”€â”€ function_testing/
â”‚       â”œâ”€â”€ main.c
â”‚       â”œâ”€â”€ math_functions.c
â”‚       â”œâ”€â”€ math_functions.h
â”‚       â””â”€â”€ program
â”œâ”€â”€ imgs/
â”‚   â””â”€â”€ bishopDL.jpg
â”œâ”€â”€ Karapathy/
â”‚   â”œâ”€â”€ GPT_from_scratch/
â”‚   â”‚   â”œâ”€â”€ bigram.ipynb
â”‚   â”‚   â”œâ”€â”€ BLT.ipynb
â”‚   â”‚   â”œâ”€â”€ gpt-dev.ipynb
â”‚   â”‚   â”œâ”€â”€ input.txt
â”‚   â”‚   â””â”€â”€ token.ipynb
â”‚   â”œâ”€â”€ gpt-2/
â”‚   â”‚   â”œâ”€â”€ hellaswag.py
â”‚   â”‚   â”œâ”€â”€ play.ipynb
â”‚   â”‚   â””â”€â”€ train_gpt2.py
â”‚   â””â”€â”€ makemore/
â”‚       â””â”€â”€ 1.ipynb
â”œâ”€â”€ random_code/
â”‚   â”œâ”€â”€ a2a-samples/
â”‚   â”œâ”€â”€ algoverse/
â”‚   â”‚   â”œâ”€â”€ micro_grad_code.ipynb
â”‚   â”‚   â”œâ”€â”€ section-1-evaluations.ipynb
â”‚   â”‚   â””â”€â”€ section-2-interpretability.ipynb
â”‚   â”œâ”€â”€ aws/
â”‚   â”‚   â”œâ”€â”€ amazon-bedrock-workshop/
â”‚   â”‚   â”œâ”€â”€ answer-matcher-gaming/
â”‚   â”‚   â”‚   â”œâ”€â”€ bedrock_eval.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chroma_rules/
â”‚   â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”œâ”€â”€ dockerfile
â”‚   â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”œâ”€â”€ rulebook.py
â”‚   â”‚   â”‚   â””â”€â”€ rulebook.toml
â”‚   â”‚   â””â”€â”€ aws_testing.ipynb
â”‚   â”œâ”€â”€ chonkie/
â”‚   â”‚   â””â”€â”€ first_attempt.ipynb
â”‚   â”œâ”€â”€ crewai/
â”‚   â”‚   â”œâ”€â”€ agentic_sales_pipeline/
â”‚   â”‚   â”‚   â”œâ”€â”€ code.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â”‚   â””â”€â”€ crewai_flow.html
â”‚   â”‚   â”œâ”€â”€ ai_news/
â”‚   â”‚   â”‚   â”œâ”€â”€ news/
â”‚   â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â””â”€â”€ uv.lock
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ fastapi_app/
â”‚   â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ fastapi_crew/
â”‚   â”‚   â”‚   â”œâ”€â”€ knowledge/
â”‚   â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â””â”€â”€ uv.lock
â”‚   â”‚   â”œâ”€â”€ meeting_minutes/
â”‚   â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ video_analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ knowledge/
â”‚   â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ uv.lock
â”‚   â”‚   â”‚   â”œâ”€â”€ video.mp3
â”‚   â”‚   â”‚   â””â”€â”€ video.mp4
â”‚   â”‚   â””â”€â”€ video_with_gpt/
â”‚   â”‚       â”œâ”€â”€ pyproject.toml
â”‚   â”‚       â”œâ”€â”€ README.md
â”‚   â”‚       â”œâ”€â”€ result.txt
â”‚   â”‚       â””â”€â”€ src/
â”‚   â”œâ”€â”€ demaned_forecast_kaggle/
â”‚   â”‚   â””â”€â”€ code.ipynb
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ fastapi/
â”‚   â”‚   â”‚   â”œâ”€â”€ compose.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ model_starter.py
â”‚   â”‚   â”‚   â”œâ”€â”€ README.Docker.md
â”‚   â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”‚   â””â”€â”€ test_call.py
â”‚   â”‚   â””â”€â”€ simple/
â”‚   â”‚       â”œâ”€â”€ Dockerfile
â”‚   â”‚       â””â”€â”€ main.py
â”‚   â”œâ”€â”€ dpsy/
â”‚   â”‚   â””â”€â”€ first_try.ipynb
â”‚   â”œâ”€â”€ fastapi/
â”‚   â”‚   â”œâ”€â”€ basic/
â”‚   â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚   â””â”€â”€ vercel/
â”‚   â”œâ”€â”€ finbert sentiment analysis/
â”‚   â”‚   â””â”€â”€ code.ipynb
â”‚   â”œâ”€â”€ hf/
â”‚   â”‚   â””â”€â”€ small_course/
â”‚   â”‚       â””â”€â”€ chapter_1/
â”‚   â”œâ”€â”€ lancedb/
â”‚   â”‚   â”œâ”€â”€ cohere_reranker.ipynb
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ langgraph/
â”‚   â”‚   â”œâ”€â”€ arxiv_paper_agent_nemo/
â”‚   â”‚   â””â”€â”€ react.ipynb
â”‚   â”œâ”€â”€ llm_eval/
â”‚   â”‚   â”œâ”€â”€ logprob_learnings.ipynb
â”‚   â”‚   â””â”€â”€ ragas.ipynb
â”‚   â”œâ”€â”€ LLM_from_scratch/
â”‚   â”‚   â”œâ”€â”€ chapter_2/
â”‚   â”‚   â”œâ”€â”€ chapter_3/
â”‚   â”‚   â”œâ”€â”€ chapter_4/
â”‚   â”‚   â””â”€â”€ chapter_5/
â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â”œâ”€â”€ proj_1/
â”‚   â”‚   â””â”€â”€ proj_2/
â”‚   â”œâ”€â”€ mlz/
â”‚   â”‚   â”œâ”€â”€ 1/
â”‚   â”‚   â”œâ”€â”€ 2/
â”‚   â”‚   â”œâ”€â”€ 3/
â”‚   â”‚   â””â”€â”€ 4/
â”‚   â”œâ”€â”€ neofetch/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ mine.png
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”œâ”€â”€ news_hub/
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”œâ”€â”€ NM/
â”‚   â”‚   â”œâ”€â”€ code_algo_eval.ipynb
â”‚   â”‚   â”œâ”€â”€ code.ipynb
â”‚   â”‚   â”œâ”€â”€ nlm_quoraQuestions_WeightedWords_Tokenization.ipynb
â”‚   â”‚   â””â”€â”€ train.csv.zip
â”‚   â”œâ”€â”€ openai_video_process/
â”‚   â”‚   â”œâ”€â”€ process_video.ipynb
â”‚   â”‚   â”œâ”€â”€ video.mp3
â”‚   â”‚   â””â”€â”€ video.mp4
â”‚   â”œâ”€â”€ quick_codes/
â”‚   â”‚   â”œâ”€â”€ assistant.py
â”‚   â”‚   â”œâ”€â”€ quick_access.ipynb
â”‚   â”‚   â””â”€â”€ testing_in_notebooks.ipynb
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â””â”€â”€ semantic cache.ipynb
â”‚   â”œâ”€â”€ smol_course/
â”‚   â”‚   â”œâ”€â”€ dpo_finetuning_example.ipynb
â”‚   â”‚   â”œâ”€â”€ orpo_finetuning_example.ipynb
â”‚   â”‚   â”œâ”€â”€ sft_peft.ipynb
â”‚   â”‚   â””â”€â”€ smol_agent.ipynb
â”‚   â”œâ”€â”€ time_series/
â”‚   â”‚   â””â”€â”€ timesfm/
â”‚   â”œâ”€â”€ unsloth/
â”‚   â”‚   â””â”€â”€ llama_synthdata_finetune.ipynb
â””â”€â”€ resume/
    â””â”€â”€ Kevork Sulahian.pdf
```
</details>

## âœ… Completed Projects/Code and Learning
- [FinMAs](https://github.com/KevorkSulahian/agentic-llm-for-better-results)  
- [Byte Latent mini implemntation](./Karapathy/GPT_from_scratch/BLT.ipynb), mine has a static patches 4 bites each.  
- [NeoFetch](./random_code/neofetch/README.md) yes i use windows :/  
- [Karapathy minbpe](https://github.com/karpathy/minbpe) done [here](./Karapathy/GPT_from_scratch/token.ipynb)
- [Learning C cc4e](https://www.cc4e.com/) kinda finished most of the book 
- I have older stuff but I'm still too lazy to add them  

## ğŸ“ my articles
#### Note: some of the articles are basically implementation of tutorials so not fully mine
- [Demystifying DeepSeekMathâ€™s Data Pipeline: A FastText-Based Reproduction and Analysis](https://huggingface.co/blog/herooooooooo/demystifying-deepseekmaths-data-pipeline-a-fasttex). Simply summarized, how they are classifying the data that they captured online.  
- [Financial Analysis With Langchain and Crewai](https://huggingface.co/blog/herooooooooo/financial-analysis-with-langchain-and-crewai) some testing from langchain and crewai docs  
- [Automate Job Applications](https://huggingface.co/blog/herooooooooo/automation-job-applications-with-python-and-ollama) auto-rejection deserves auto-apply  
- [FineTune Clip](https://medium.com/@kevork.ysulahian/finetune-clip-with-huggingface-2f0abc23c57c)  
- [Zero-shot Classification](https://medium.com/@kevork.ysulahian/zero-shot-classification-and-detection-made-simple-with-huggingface-000d63d53bfe)  
- [Data Scrapping project with R](https://medium.com/@kevork.ysulahian/real-life-data-scrapping-project-scrapping-job-postings-with-r-47a6091f4866)  
- [My First C project](https://huggingface.co/blog/herooooooooo/c-first-project)  

## ğŸš§ Things I'm working on right now
- [FinMAs](https://github.com/KevorkSulahian/agentic-llm-for-better-results) working (slowly) on adding vision and updating the crew to work with flow/  
- [I will need to pour my life into this](https://x.com/rasbt/status/1790007260615217156)  
- [neetcode a day keeps the unemployment away](https://neetcode.io/courses)  
- Also reading ![Bishop Deep Learning](./imgs/bishopDL.jpg) it's a new theoretical reintro to the math and theory  
- [deep ml exercises](https://www.deep-ml.com/)  
- [nand game](https://nandgame.com/)  
- [puzzles](https://www.cs.cmu.edu/puzzle/)  
- [A long list of open problems and concrete projects in evals](https://docs.google.com/document/d/1gi32-HZozxVimNg5Mhvk4CvW4zq8J12rGmK_j2zxNEg/edit?pli=1&tab=t.0#heading=h.q14pjbvzx1x)  

### Self-improvement guides
- [write better code](https://marvelousmlops.substack.com/p/bridging-the-gap-converting-data)  
- [Document your grind](https://lelouch.dev/blog/august-2024/documenting-your-grind/)  
- [Reclaiming your attention and focus - Unc advice for the world](https://x.com/LukasHozda/status/1860442337534468333)  
- [Machine Learning Interviews](https://huyenchip.com/machine-learning-systems-design/toc.html)  
- [LLM (ML) Job Interviews (Fall 2024) - Process](https://mimansajaiswal.github.io/posts/llm-ml-job-interviews-fall-2024-process/)
- [How To work in with Mentors or managers](https://medium.com/@jurgens_24580/reflections-on-strategies-for-successful-meetings-with-undergraduate-researchers-ae22306ecd8d)

## ğŸ“š Completed stuff that I recommend
- [LLama from scratch](https://blog.briankitano.com/llama-from-scratch/#:~:text=Before%20you%20even%20look%20at,and%20evaluating%20as%20you%20go) I really enjoyed how this person was implementing the paper, use it to implement future papers.  
- [Reward Hacking](https://lilianweng.github.io/posts/2024-11-28-reward-hacking/) what could go wrong in RLHF  
- [LLM tuning and alignment series by HF](https://argilla.io/blog/mantisnlp-rlhf-part-8/) Explains different techniques  
- [What Weâ€™ve Learned From A Year of Building with LLMs](https://applied-llms.org/) Guide to building llms from exp  
- [Byte Latent Transformer: Patches Scale Better  
Than Tokens](https://arxiv.org/pdf/2412.09871) instead of a single byte, they use patches, which could scale better with images in the future  
- [High-Quality Human Data](https://lilianweng.github.io/posts/2024-02-05-human-data-quality/) How human data is made, based on what I do daily, this is a helpful read. It's not always about the model...  
- [The Illustrated DeepSeek-R1](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1)  
- [A vision researcherâ€™s guide to some RL stuff: PPO & GRPO](https://yugeten.github.io/posts/2025/01/ppogrpo/)  
- [understanding-multimodal-llms](https://magazine.sebastianraschka.com/p/understanding-multimodal-llms)  
- I highly recommend the [A vision researcherâ€™s guide to some RL stuff](https://yugeten.github.io/posts/2025/01/ppogrpo/) for its simplicity  
- [AI progress visualized](https://theaidigest.org/progress-and-dangers), it's a really fun read.  
- [The State of Reinforcement Learning for LLM Reasoning - 2025](https://magazine.sebastianraschka.com/p/the-state-of-llm-reasoning-model-training?utm_campaign=post) would be worth to go over the papers at the end one more time.  
- [Sabotage Evaluations for Frontier Models](https://arxiv.org/pdf/2410.21514) Great paper on evals  
- [KL Divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)  
- [Momentum](https://distill.pub/2017/momentum/)  
- [BroadCasting](https://numpy.org/doc/stable/user/basics.broadcasting.html) how python works  
- [Singular Vector Decomposition](https://gregorygundersen.com/blog/2018/12/10/svd/)  
- [GRPO Video explenation](https://youtu.be/XeUB4h1OO1g?si=UwQiG3az286G4b1c)  
- [Visual info](https://colah.github.io/posts/2015-09-Visual-Information/) pretty decent article would read again.  
- [diffusion-theory-from-scratch](https://iclr-blogposts.github.io/2024/blog/diffusion-theory-from-scratch/)  

## tiny achievements
- [HF smol course](https://github.com/huggingface/smol-course). Small but super nice intro to using HF finetuning and more.  
- [learnpytorch.io mostly following and not much else](https://www.learnpytorch.io/)  
- [hf agents](https://huggingface.co/learn/agents-course)  

## To do in the future

#### Blogs
##### Blog writers
- [ML Blogs](https://cneuralnets.netlify.app/mlblogs)  
- [hackerllama](https://osanseviero.github.io/hackerllama/blog/)  
- [eugeneyan](https://eugeneyan.com/start-here/)  

##### Just a blog
- [GNN intro](https://distill.pub/2021/gnn-intro/)  
- [Understanding Multimodal LLMs](https://magazine.sebastianraschka.com/p/understanding-multimodal-llms)  
- [Physics of Language Models](https://antaripasaha.notion.site/Physics-of-Language-Models-understanding-hidden-reasoning-process-1045314a563980c68566e4ecc1e32ef6)  
- [Policy Gradient](https://lilianweng.github.io/posts/2018-04-08-policy-gradient/)  
- [Flash Attention](https://benjaminwarner.dev/2023/08/16/flash-attention-compile)  
- [LLM visualized](https://bbycroft.net/llm)  
- [LLM training](https://rentry.org/llm-training)  
- [LLM Research Insights:](https://magazine.sebastianraschka.com/p/llm-research-insights-instruction?)  
- [FineWeb: decanting the web for the finest text data at scale](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1)  
- [torch.compile, the missing manual](https://docs.google.com/document/d/1y5CRfMLdwEoF1nTk9q8qEu1mgMUuUtvhklPKJ2emLU8/edit?tab=t.0#heading=h.66t0x3z84jio)  
- [Build a GENAI platform](https://huyenchip.com/2024/07/25/genai-platform.html)  
- [New LLM Pre-training and Post-training Paradigms](https://magazine.sebastianraschka.com/p/new-llm-pre-training-and-post-training)  

## Maybe things

### Courses
- [parallel computing](https://gfxcourses.stanford.edu/cs149/fall24/courseinfo)  
- [harvard research class](https://docs.google.com/document/d/1uvAbEhbgS_M-uDMTzmOWRlYxqCkogKRXdbKYYT98ooc/edit?pli=1&tab=t.0#heading=h.o3hogvl0ayc1)  
- [ML Engineering](https://github.com/stas00/ml-engineering)  
- [Financial RL](https://github.com/AI4Finance-Foundation/FinRL/tree/c34190153d84c376dcacaf18b57097a6272b0286)  
- [Open AI RL](https://spinningup.openai.com/en/latest/)  

### Code
- [video tracking](https://github.com/roboflow/supervision)  
- [dspy rag](https://www.kaggle.com/code/iamleonie/rag-with-gemma-on-hf-and-weaviate-in-dspy)  
- [Write your Own Virtual Machine](https://www.jmeiners.com/lc3-vm/)  

- [Competitive Programmerâ€™s Handbook](https://cses.fi/book/book.pdf)  
- [HPC](https://en.algorithmica.org/hpc/complexity/)  
- [What Every Programmer Should Know About Memory](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf)
