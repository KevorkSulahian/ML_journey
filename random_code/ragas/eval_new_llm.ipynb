{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05c2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a discount calculation assistant. I will provide a customer profile and you must calculate their discount percentage and explain your reasoning.\n",
    "\n",
    "Discount rules:\n",
    "- Age 65+ OR student status: 15% discount\n",
    "- Annual income < $30,000: 20% discount  \n",
    "- Premium member for 2+ years: 10% discount\n",
    "- New customer (< 6 months): 5% discount\n",
    "\n",
    "Rules can stack up to a maximum of 35% discount.\n",
    "\n",
    "Respond in JSON format only:\n",
    "{\n",
    "  \"discount_percentage\": number,\n",
    "  \"reason\": \"clear explanation of which rules apply and calculations\",\n",
    "  \"applied_rules\": [\"list\", \"of\", \"applied\", \"rule\", \"names\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33bd9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "import asyncio\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1312d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL = \"gpt-4.1-nano-2025-04-14\"\n",
    "\n",
    "def get_client() -> AsyncOpenAI:\n",
    "    \"\"\"Lazily create an AsyncOpenAI client, requiring the API key only when used.\n",
    "\n",
    "    This avoids raising errors during module import (e.g., when running --help).\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\n",
    "            \"OPENAI_API_KEY is not set. Please export it before running prompts.\"\n",
    "        )\n",
    "    return AsyncOpenAI(api_key=api_key)\n",
    "\n",
    "\n",
    "async def run_prompt(prompt: str, model: str = DEFAULT_MODEL):\n",
    "    \"\"\"Run the discount calculation prompt with the specified model.\"\"\"\n",
    "    client = get_client()\n",
    "    response = await client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = response.choices[0].message.content.strip()\n",
    "    return response\n",
    "\n",
    "\n",
    "async def main():\n",
    "    customer_profile = \"\"\"\n",
    "    Customer Profile:\n",
    "    - Name: Sarah Johnson\n",
    "    - Age: 67\n",
    "    - Student: No\n",
    "    - Annual Income: $45,000\n",
    "    - Premium Member: Yes, for 3 years\n",
    "    - Account Age: 3 years\n",
    "    \"\"\"\n",
    "    print(\"=== System Prompt ===\")\n",
    "    print(SYSTEM_PROMPT)\n",
    "    print(\"\\n=== Customer Profile ===\")\n",
    "    print(customer_profile)\n",
    "    print(f\"\\n=== Running Prompt with default model {DEFAULT_MODEL} ===\")\n",
    "    print(await run_prompt(customer_profile, model=DEFAULT_MODEL))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81cdc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"discount_percentage\": 25,\n",
      "  \"reason\": \"Sarah is eligible for a 15% discount due to age being over 65. Additionally, her premium membership duration of over 2 years grants a 10% discount. These discounts stack for a total of 25%. No other rules apply as she is not a student, does not have income below $30,000, and is not a new customer.\",\n",
      "  \"applied_rules\": [\"Age 65+\", \"Premium member for 2+ years\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test with a sample customer profile\n",
    "customer_profile = \"\"\"\n",
    "Customer Profile:\n",
    "- Name: Sarah Johnson\n",
    "- Age: 67\n",
    "- Student: No\n",
    "- Annual Income: $45,000\n",
    "- Premium Member: Yes, for 3 years\n",
    "- Account Age: 3 years\n",
    "\"\"\"\n",
    "\n",
    "result = await run_prompt(customer_profile)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c452a96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.path.abspath(\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af66cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset import Dataset\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"Load the dataset from CSV file. Downloads from GitHub if not found locally.\"\"\"\n",
    "    import urllib.request\n",
    "    # Get the current working directory (notebook's directory)\n",
    "    current_dir = os.getcwd()\n",
    "    dataset_path = os.path.join(current_dir, \"datasets\", \"discount_benchmark.csv\")\n",
    "    # Download dataset from GitHub if it doesn't exist locally\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.makedirs(os.path.dirname(dataset_path), exist_ok=True)\n",
    "        urllib.request.urlretrieve(\"https://raw.githubusercontent.com/vibrantlabsai/ragas/main/examples/ragas_examples/benchmark_llm/datasets/discount_benchmark.csv\", dataset_path)\n",
    "    return Dataset.load(name=\"discount_benchmark\", backend=\"local/csv\", root_dir=current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ragas.metrics.discrete import discrete_metric\n",
    "from ragas.metrics.result import MetricResult\n",
    "\n",
    "@discrete_metric(name=\"discount_accuracy\", allowed_values=[\"correct\", \"incorrect\"])\n",
    "def discount_accuracy(prediction: str, expected_discount):\n",
    "    \"\"\"Check if the discount prediction is correct.\"\"\"\n",
    "    \n",
    "\n",
    "    parsed_json = json.loads(prediction)\n",
    "    predicted_discount = parsed_json.get(\"discount_percentage\")\n",
    "    expected_discount_int = int(expected_discount)\n",
    "\n",
    "    if predicted_discount == expected_discount_int:\n",
    "        return MetricResult(\n",
    "            value=\"correct\", \n",
    "            reason=f\"Correctly calculated discount={expected_discount_int}%\"\n",
    "        )\n",
    "    else:\n",
    "        return MetricResult(\n",
    "            value=\"incorrect\",\n",
    "            reason=f\"Expected discount={expected_discount_int}%; Got discount={predicted_discount}%\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b2b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import experiment\n",
    "\n",
    "@experiment()\n",
    "async def benchmark_experiment(row, model_name: str):\n",
    "    # Get model response\n",
    "    response = await run_prompt(row[\"customer_profile\"], model=model_name)\n",
    "\n",
    "    # Parse response (strict JSON mode expected)\n",
    "    try:\n",
    "        parsed_json = json.loads(response)\n",
    "        predicted_discount = parsed_json.get('discount_percentage')\n",
    "    except Exception:\n",
    "        predicted_discount = None\n",
    "\n",
    "    # Score the response\n",
    "    score = discount_accuracy.score(\n",
    "        prediction=response,\n",
    "        expected_discount=row[\"expected_discount\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        **row,\n",
    "        \"model\": model_name,\n",
    "        \"response\": response,\n",
    "        \"predicted_discount\": predicted_discount,\n",
    "        \"score\": score.value,\n",
    "        \"score_reason\": score.reason\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2214bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 10 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment: 100%|██████████| 10/10 [00:03<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running experiment: 100%|██████████| 10/10 [00:13<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset()\n",
    "print(f\"Dataset loaded with {len(dataset)} samples\")\n",
    "\n",
    "# Run baseline experiment\n",
    "baseline_results = await benchmark_experiment.arun(\n",
    "    dataset,\n",
    "    name=\"gpt-4.1-nano-2025-04-14\",\n",
    "    model_name=\"gpt-4.1-nano-2025-04-14\"\n",
    ")\n",
    "\n",
    "# Calculate and display accuracy\n",
    "baseline_accuracy = sum(1 for r in baseline_results if r[\"score\"] == \"correct\") / len(baseline_results)\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.2%}\")\n",
    "\n",
    "# Run candidate experiment\n",
    "candidate_results = await benchmark_experiment.arun(\n",
    "    dataset,\n",
    "    name=\"gpt-5-nano-2025-08-07\",\n",
    "    model_name=\"gpt-5-nano-2025-08-07\"\n",
    ")\n",
    "\n",
    "# Calculate and display accuracy\n",
    "candidate_accuracy = sum(1 for r in candidate_results if r[\"score\"] == \"correct\") / len(candidate_results)\n",
    "print(f\"Candidate Accuracy: {candidate_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55c7ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "import datetime\n",
    "\n",
    "def compare_inputs_to_output(\n",
    "    inputs: List[str], output_path: Optional[str] = None\n",
    ") -> str:\n",
    "    \"\"\"Compare multiple experiment CSVs and write a combined CSV.\n",
    "\n",
    "    - Requires 'id' column in all inputs; uses it as the alignment key\n",
    "    - Builds output with id + canonical columns + per-experiment response/score/reason columns\n",
    "    - Returns the full output path\n",
    "    \"\"\"\n",
    "    if not inputs or len(inputs) < 2:\n",
    "        raise ValueError(\"At least two input CSV files are required for comparison\")\n",
    "\n",
    "    # Load all inputs\n",
    "    dataframes = []\n",
    "    experiment_names = []\n",
    "    for path in inputs:\n",
    "        df = pd.read_csv(path)\n",
    "        if \"model\" not in df.columns:\n",
    "            raise ValueError(f\"Missing 'model' column in {path}\")\n",
    "        exp_name = str(df[\"model\"].iloc[0])\n",
    "        experiment_names.append(exp_name)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    canonical_cols = [\"customer_profile\", \"description\", \"expected_discount\"]\n",
    "    base_df = dataframes[0]\n",
    "\n",
    "    # Require 'id' in all inputs\n",
    "    if not all(\"id\" in df.columns for df in dataframes):\n",
    "        raise ValueError(\n",
    "            \"All input CSVs must contain an 'id' column to align rows. Re-run experiments after adding 'id' to your dataset.\"\n",
    "        )\n",
    "\n",
    "    # Validate duplicates and matching sets of IDs\n",
    "    key_sets = []\n",
    "    for idx, df in enumerate(dataframes):\n",
    "        keys = df[\"id\"].astype(str)\n",
    "        if keys.duplicated().any():\n",
    "            dupes = keys[keys.duplicated()].head(3).tolist()\n",
    "            raise ValueError(\n",
    "                f\"Input {inputs[idx]} contains duplicate id values. Examples: {dupes}\"\n",
    "            )\n",
    "        key_sets.append(set(keys.tolist()))\n",
    "\n",
    "    base_keys = key_sets[0]\n",
    "    for i, ks in enumerate(key_sets[1:], start=1):\n",
    "        if ks != base_keys:\n",
    "            missing_in_other = list(base_keys - ks)[:5]\n",
    "            missing_in_base = list(ks - base_keys)[:5]\n",
    "            raise ValueError(\n",
    "                \"Inputs do not contain the same set of IDs.\\n\"\n",
    "                f\"- Missing in file {i + 1}: {missing_in_other}\\n\"\n",
    "                f\"- Extra in file {i + 1}: {missing_in_base}\"\n",
    "            )\n",
    "\n",
    "    # Validate canonical columns exist in base\n",
    "    missing = [c for c in canonical_cols if c not in base_df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"First CSV missing required columns: {missing}\")\n",
    "\n",
    "    # Build combined on base order using 'id' as alignment key\n",
    "    base_ids_str = base_df[\"id\"].astype(str)\n",
    "    combined = base_df[[\"id\"] + canonical_cols].copy()\n",
    "\n",
    "    # Append per-experiment outputs by aligned ID\n",
    "    for df, exp_name in zip(dataframes, experiment_names):\n",
    "        df = df.copy()\n",
    "        df[\"id\"] = df[\"id\"].astype(str)\n",
    "        df = df.set_index(\"id\")\n",
    "        for col in [\"response\", \"score\", \"score_reason\"]:\n",
    "            if col not in df.columns:\n",
    "                raise ValueError(\n",
    "                    f\"Column '{col}' not found in one input. Please provide per-row '{col}'.\"\n",
    "                )\n",
    "        combined[f\"{exp_name}_response\"] = base_ids_str.map(df[\"response\"])\n",
    "        combined[f\"{exp_name}_score\"] = base_ids_str.map(df[\"score\"])\n",
    "        combined[f\"{exp_name}_score_reason\"] = base_ids_str.map(df[\"score_reason\"])\n",
    "\n",
    "    # Determine output path\n",
    "    current_dir = os.getcwd()\n",
    "    experiments_dir = os.path.join(current_dir, \"experiments\")\n",
    "    os.makedirs(experiments_dir, exist_ok=True)\n",
    "\n",
    "    if output_path is None or output_path.strip() == \"\":\n",
    "        run_id = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        output_path = os.path.join(experiments_dir, f\"{run_id}-comparison.csv\")\n",
    "    else:\n",
    "        # If relative path, place under experiments dir\n",
    "        if not os.path.isabs(output_path):\n",
    "            output_path = os.path.join(experiments_dir, output_path)\n",
    "\n",
    "    # Sort by id for user-friendly reading\n",
    "    if \"id\" in combined.columns:\n",
    "        combined = combined.sort_values(by=\"id\").reset_index(drop=True)\n",
    "    combined.to_csv(output_path, index=False)\n",
    "\n",
    "    # Print per-experiment accuracy summary\n",
    "    for df, exp_name in zip(dataframes, experiment_names):\n",
    "        try:\n",
    "            acc = (df[\"score\"] == \"correct\").mean()\n",
    "            print(f\"{exp_name} Accuracy: {acc:.2%}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "721b81e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-nano-2025-04-14 Accuracy: 50.00%\n",
      "gpt-5-nano-2025-08-07 Accuracy: 100.00%\n",
      "Comparison saved to: /Users/ksulahian/ML_journey/random_code/ragas/experiments/20251212-160802-comparison.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compare the two experiment results\n",
    "# Update these paths to match your actual experiment output files\n",
    "output_path = compare_inputs_to_output(\n",
    "    inputs=[\n",
    "        \"experiments/gpt-4.1-nano-2025-04-14.csv\",\n",
    "        \"experiments/gpt-5-nano-2025-08-07.csv\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Comparison saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d24706e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>expected_discount</th>\n",
       "      <th>gpt-4.1-nano-2025-04-14_response</th>\n",
       "      <th>gpt-4.1-nano-2025-04-14_score</th>\n",
       "      <th>gpt-4.1-nano-2025-04-14_score_reason</th>\n",
       "      <th>gpt-5-nano-2025-08-07_response</th>\n",
       "      <th>gpt-5-nano-2025-08-07_score</th>\n",
       "      <th>gpt-5-nano-2025-08-07_score_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Martha is a 70-year-old retiree who enjoys gar...</td>\n",
       "      <td>Senior only</td>\n",
       "      <td>15</td>\n",
       "      <td>{\\n  \"discount_percentage\": 15,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=15%</td>\n",
       "      <td>{\\n  \"discount_percentage\": 15,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arjun, aged 19, is a full-time computer-scienc...</td>\n",
       "      <td>Student only</td>\n",
       "      <td>15</td>\n",
       "      <td>{\\n  \"discount_percentage\": 0,\\n  \"reason\": \"N...</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>Expected discount=15%; Got discount=0%</td>\n",
       "      <td>{\\n  \"discount_percentage\": 15,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cynthia, a 40-year-old freelance artist, earns...</td>\n",
       "      <td>Low income only</td>\n",
       "      <td>20</td>\n",
       "      <td>{\\n  \"discount_percentage\": 20,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=20%</td>\n",
       "      <td>{\\n  \"discount_percentage\": 20,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mr. Ocampo is 68, lives on social security of ...</td>\n",
       "      <td>Senior, low income, new customer (capped)</td>\n",
       "      <td>35</td>\n",
       "      <td>{\\n  \"discount_percentage\": 35,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=35%</td>\n",
       "      <td>{\\n  \"discount_percentage\": 35,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hannah is a 24-year-old postgraduate student d...</td>\n",
       "      <td>Student, low income, premium 3 yrs (capped)</td>\n",
       "      <td>35</td>\n",
       "      <td>{\\n  \"discount_percentage\": 35,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=35%</td>\n",
       "      <td>{\\n  \"discount_percentage\": 35,\\n  \"reason\": \"...</td>\n",
       "      <td>correct</td>\n",
       "      <td>Correctly calculated discount=35%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                   customer_profile  \\\n",
       "0   1  Martha is a 70-year-old retiree who enjoys gar...   \n",
       "1   2  Arjun, aged 19, is a full-time computer-scienc...   \n",
       "2   3  Cynthia, a 40-year-old freelance artist, earns...   \n",
       "3   4  Mr. Ocampo is 68, lives on social security of ...   \n",
       "4   5  Hannah is a 24-year-old postgraduate student d...   \n",
       "\n",
       "                                   description  expected_discount  \\\n",
       "0                                  Senior only                 15   \n",
       "1                                 Student only                 15   \n",
       "2                              Low income only                 20   \n",
       "3    Senior, low income, new customer (capped)                 35   \n",
       "4  Student, low income, premium 3 yrs (capped)                 35   \n",
       "\n",
       "                    gpt-4.1-nano-2025-04-14_response  \\\n",
       "0  {\\n  \"discount_percentage\": 15,\\n  \"reason\": \"...   \n",
       "1  {\\n  \"discount_percentage\": 0,\\n  \"reason\": \"N...   \n",
       "2  {\\n  \"discount_percentage\": 20,\\n  \"reason\": \"...   \n",
       "3  {\\n  \"discount_percentage\": 35,\\n  \"reason\": \"...   \n",
       "4  {\\n  \"discount_percentage\": 35,\\n  \"reason\": \"...   \n",
       "\n",
       "  gpt-4.1-nano-2025-04-14_score    gpt-4.1-nano-2025-04-14_score_reason  \\\n",
       "0                       correct       Correctly calculated discount=15%   \n",
       "1                     incorrect  Expected discount=15%; Got discount=0%   \n",
       "2                       correct       Correctly calculated discount=20%   \n",
       "3                       correct       Correctly calculated discount=35%   \n",
       "4                       correct       Correctly calculated discount=35%   \n",
       "\n",
       "                      gpt-5-nano-2025-08-07_response  \\\n",
       "0  {\\n  \"discount_percentage\": 15,\\n  \"reason\": \"...   \n",
       "1  {\\n  \"discount_percentage\": 15,\\n  \"reason\": \"...   \n",
       "2  {\\n  \"discount_percentage\": 20,\\n  \"reason\": \"...   \n",
       "3  {\\n  \"discount_percentage\": 35,\\n  \"reason\": \"...   \n",
       "4  {\\n  \"discount_percentage\": 35,\\n  \"reason\": \"...   \n",
       "\n",
       "  gpt-5-nano-2025-08-07_score gpt-5-nano-2025-08-07_score_reason  \n",
       "0                     correct  Correctly calculated discount=15%  \n",
       "1                     correct  Correctly calculated discount=15%  \n",
       "2                     correct  Correctly calculated discount=20%  \n",
       "3                     correct  Correctly calculated discount=35%  \n",
       "4                     correct  Correctly calculated discount=35%  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_csv(output_path)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943f0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
